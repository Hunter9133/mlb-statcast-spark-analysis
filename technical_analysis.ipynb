{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj1cNi8-OUHu"
      },
      "outputs": [],
      "source": [
        " !wget https://github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.24%2B8/OpenJDK11U-jdk_x64_linux_hotspot_11.0.24_8.tar.gz\n",
        "!tar xzf OpenJDK11U-jdk_x64_linux_hotspot_11.0.24_8.tar.gz\n",
        "!rm OpenJDK11U-jdk_x64_linux_hotspot_11.0.24_8.tar.gz\n",
        "!wget https://archive.apache.org/dist/spark/spark-3.5.2/spark-3.5.2-bin-hadoop3.tgz\n",
        "!tar xzf spark-3.5.2-bin-hadoop3.tgz\n",
        "!rm spark-3.5.2-bin-hadoop3.tgz\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "working_dir = subprocess.run(['pwd'], stdout = subprocess.PIPE).stdout.strip().decode(\"utf-8\")\n",
        "print(working_dir)\n",
        "os.environ[\"JAVA_HOME\"] = working_dir + \"/jdk-11.0.24+8/\"\n",
        "os.environ[\"SPARK_HOME\"] = working_dir + \"/spark-3.5.2-bin-hadoop3/\"\n",
        "spark_path = os.environ['SPARK_HOME']\n",
        "sys.path.append(spark_path + \"/bin\")\n",
        "sys.path.append(spark_path + \"/python\")\n",
        "sys.path.append(spark_path + \"/python/pyspark/\")\n",
        "sys.path.append(spark_path + \"/python/lib\")\n",
        "sys.path.append(spark_path + \"/python/lib/pyspark.zip\")\n",
        "sys.path.append(spark_path + \"/python/lib/py4j-0.10.9.7-src.zip\")\n",
        "\n",
        "number_cores = 2\n",
        "memory_gb = 6"
      ],
      "metadata": {
        "id": "ahvoPf--iJIL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "import pyspark\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "conf = (pyspark.SparkConf().setMaster('local[{}]'.format(number_cores)).set('spark.driver.memory', '{}g'.format(memory_gb)))\n",
        "\n",
        "sc = pyspark.SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "5IHaACAMiLTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs pybaseball for Statcast data\n",
        "!pip install pybaseball --quiet\n",
        "\n",
        "# Imports Statcast scraper\n",
        "from pybaseball import statcast\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Downloading 2022 data...\")\n",
        "data_2022 = statcast(start_dt=\"2022-04-07\", end_dt=\"2022-10-02\")\n",
        "\n",
        "print(\"Downloading 2023 data...\")\n",
        "data_2023 = statcast(start_dt=\"2023-03-30\", end_dt=\"2023-10-01\")\n",
        "\n",
        "print(\"Downloading 2024 data... \")\n",
        "data_2024 = statcast(start_dt=\"2024-03-28\", end_dt=\"2024-09-29\")\n",
        "\n",
        "combined = pd.concat([data_2022, data_2023, data_2024])\n",
        "\n",
        "# Saving the data to a CSV may take time (took me around 13 minutes))\n",
        "combined.to_csv(\"statcast_2022_2024.csv\", index=False)\n",
        "print(\"Saved as statcast_2022_2024.csv\")\n",
        "\n",
        "# Preview row count (Spoiler alert: it should be 2,121,390)\n",
        "print(f\"Total rows: {combined.shape[0]}\")"
      ],
      "metadata": {
        "id": "Ru4tAjaR2D6O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg, count\n",
        "\n",
        "spark = SparkSession(sc)\n",
        "\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"statcast_2022_2024.csv\")\n",
        "df.printSchema()\n",
        "print(f\"Total rows: {df.count()}\")\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "pPm_lbRziN7q",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df.drop(\"player_name\")"
      ],
      "metadata": {
        "id": "LoHTkz0b0rab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pybaseball import playerid_reverse_lookup\n",
        "import pandas as pd\n",
        "\n",
        "# Gets unique batter IDs\n",
        "batter_ids = df_cleaned.select(\"batter\").distinct().toPandas()\n",
        "batter_ids = batter_ids[\"batter\"].dropna().astype(int).tolist()\n",
        "\n",
        "# Reverse lookup to get names\n",
        "lookup_df = playerid_reverse_lookup(batter_ids, key_type='mlbam')\n",
        "lookup_df['batter'] = lookup_df['key_mlbam']\n",
        "lookup_df['player_name'] = lookup_df['name_first'] + ' ' + lookup_df['name_last']\n",
        "\n",
        "# Renames player_name\n",
        "lookup_df = lookup_df.rename(columns={\"player_name\": \"batter_name\"})\n",
        "\n",
        "lookup_df = lookup_df[['batter', 'batter_name']]"
      ],
      "metadata": {
        "id": "O6Pvj0Al12dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_spark_df = spark.createDataFrame(lookup_df)\n",
        "df_with_names = df.drop(\"player_name\").join(lookup_spark_df, on=\"batter\", how=\"left\")"
      ],
      "metadata": {
        "id": "cqSu4VtD2YUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter and Aggregate Hitter Statistics\n",
        "\n",
        "In this step, I filtered for batted balls with complete tracking data: exit velocity (launch_speed), launch angle (launch_angle), and estimated hit distance (hit_distance_sc). Then I grouped by batter and calculated the average of each metric. To reduce noise from small sample sizes, I also filtered out hitters with fewer than 50 batted ball events.\n"
      ],
      "metadata": {
        "id": "9oVk_dbRmvcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batted_balls = df_with_names.filter(\n",
        "    (col(\"launch_speed\").isNotNull()) &\n",
        "    (col(\"launch_angle\").isNotNull()) &\n",
        "    (col(\"events\").isNotNull())\n",
        ")\n",
        "\n",
        "hitter_stats = (\n",
        "    batted_balls.groupBy(\"batter\", \"batter_name\")\n",
        "    .agg(\n",
        "        avg(\"launch_speed\").alias(\"avg_exit_velocity\"),\n",
        "        avg(\"launch_angle\").alias(\"avg_launch_angle\"),\n",
        "        avg(\"hit_distance_sc\").alias(\"avg_hit_distance\"),\n",
        "        count(\"*\").alias(\"num_batted_balls\")\n",
        "    )\n",
        "    .filter(col(\"num_batted_balls\") >= 50)\n",
        ")"
      ],
      "metadata": {
        "id": "VixOyZNk_ha_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorization, Scaling, and K-Means Clustering\n",
        "\n",
        "I used Spark's MLlib to build a pipeline that performs the following:\n",
        "1. Combines the hitting stats into a feature vector\n",
        "2. Standardizes the features using StandardScaler\n",
        "3. Applies K-Means clustering with k = 4 to segment hitters into groups based on their hitting profiles"
      ],
      "metadata": {
        "id": "aif7oFwAnAOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"avg_exit_velocity\", \"avg_launch_angle\", \"avg_hit_distance\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"features\",\n",
        "    outputCol=\"scaled_features\",\n",
        "    withMean=True,\n",
        "    withStd=True\n",
        ")"
      ],
      "metadata": {
        "id": "M6g0gBUD_oSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "kmeans = KMeans(featuresCol=\"scaled_features\", k=4, seed=42, predictionCol=\"cluster\")\n",
        "\n",
        "pipeline = Pipeline(stages=[assembler, scaler, kmeans])\n",
        "model = pipeline.fit(hitter_stats)\n",
        "\n",
        "clustered_data = model.transform(hitter_stats).select(\n",
        "    \"batter_name\", \"avg_exit_velocity\", \"avg_launch_angle\",\n",
        "    \"avg_hit_distance\", \"num_batted_balls\", \"cluster\"\n",
        ")\n",
        "\n",
        "clustered_data.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVDjtMsY_tGX",
        "outputId": "8a0b9b43-9a8c-47e2-e3ca-ca6b71b9b20f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-----------------+------------------+------------------+----------------+-------+\n",
            "|       batter_name|avg_exit_velocity|  avg_launch_angle|  avg_hit_distance|num_batted_balls|cluster|\n",
            "+------------------+-----------------+------------------+------------------+----------------+-------+\n",
            "|   yasmani grandal|89.15042979942692|11.091690544412607|159.23638968481376|             698|      1|\n",
            "|      yoán moncada|88.85538752362955|13.655954631379963|172.99432892249527|             529|      0|\n",
            "|   geraldo perdomo|82.55010416666667|12.076041666666667| 147.0917622523462|             960|      3|\n",
            "|    zach mckinstry|86.80791366906475|16.610071942446044| 185.5251798561151|             695|      0|\n",
            "|      heliot ramos|90.97135549872125|10.398976982097187|164.33333333333334|             391|      1|\n",
            "|     michael busch|89.66396866840729|15.631853785900784|171.84595300261097|             383|      0|\n",
            "|      brett wisely|84.53505535055349|14.531365313653136|165.07835820895522|             271|      3|\n",
            "|     brandon nimmo|90.58940998487144| 9.595310136157337|160.61544284632853|            1322|      1|\n",
            "|vinnie pasquantino| 90.4848946135831|14.494145199063231|176.39812646370024|             854|      0|\n",
            "|         bo naylor|88.09973753280836|20.212598425196852|180.28346456692913|             381|      0|\n",
            "|          yu chang|87.83770491803274|12.103825136612022| 168.0054644808743|             183|      3|\n",
            "|       javier báez|88.05959390862942| 9.644670050761421|146.55939086294416|             985|      1|\n",
            "|     albert pujols|91.18972332015811|16.675889328063242| 176.3320158102767|             253|      0|\n",
            "|       josé fermín| 85.0133333333333| 7.809523809523809|122.63461538461539|             105|      2|\n",
            "|        zack short|85.69716981132073|19.547169811320753|175.46698113207546|             212|      0|\n",
            "|         josé siri|86.84437500000003|        14.6390625|       175.9203125|             640|      3|\n",
            "|        tom murphy|89.90769230769232|12.412587412587413|177.24475524475525|             143|      0|\n",
            "|     rafael ortega|85.92082111436947| 14.79765395894428|169.31176470588235|             341|      3|\n",
            "|      trey mancini|89.32656826568267| 12.66789667896679|170.83179297597042|             542|      1|\n",
            "|       pete alonso|89.66842501883946|16.994724943481536|179.01507159005274|            1327|      0|\n",
            "+------------------+-----------------+------------------+------------------+----------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}